{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final\n",
    "\n",
    "- Complete pipeline for Visual Similarity based Fashion Item Recommendation Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: '.\\\\yolov5'\n",
      "C:\\Users\\CrimsonX\\Shop-The-Look-main\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'detect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9516/2891950748.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.\\\\yolov5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdetect\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgenerate_bbox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'detect'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications import resnet\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "%cd .\\yolov5\n",
    "from detect import generate_bbox\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADED_MODELS = dict()\n",
    "LOADED_CSVS = dict()\n",
    "TARGET_SHAPE = (224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image1(filename):\n",
    "    \"\"\"\n",
    "    Load the specified file as a JPEG image, preprocess it and\n",
    "    resize it to the target shape for Gender Classification\n",
    "    \"\"\"\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.image.resize(image, TARGET_SHAPE[:2])\n",
    "    return tf.expand_dims(image, axis=0)\n",
    "\n",
    "def preprocess_image2(filename):\n",
    "    \"\"\"\n",
    "    Load the specified file as a JPEG image, preprocess it and\n",
    "    resize it to the target shape for Embedding Generation\n",
    "    \"\"\"\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, TARGET_SHAPE[:2])\n",
    "    image = resnet.preprocess_input(image)\n",
    "    return tf.expand_dims(image, axis=0)\n",
    "\n",
    "def load_models():\n",
    "    \"\"\"\n",
    "    Load Various Models for Recommendation Engine Pipeline\n",
    "    \"\"\"\n",
    "    if len(LOADED_MODELS) == 4:\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Loading Models...\")\n",
    "        GENDER_CLASSIFIER = load_model(\"..\\\\MODELS\\\\gender_classification_model.h5\")\n",
    "        TOPWEAR_EMBEDDING = load_model(\"..\\\\MODELS\\\\topwear_embedding.h5\")\n",
    "        BOTTOMWEAR_EMBEDDING = load_model(\"..\\\\MODELS\\\\bottomwear_embedding.h5\")\n",
    "        FOOTWEAR_EMBEDDING = load_model(\"..\\\\MODELS\\\\footwear_embedding.h5\")\n",
    "        \n",
    "        LOADED_MODELS[\"gender_classifier\"] = GENDER_CLASSIFIER\n",
    "        LOADED_MODELS[\"topwear\"] = TOPWEAR_EMBEDDING\n",
    "        LOADED_MODELS[\"bottomwear\"] = BOTTOMWEAR_EMBEDDING\n",
    "        LOADED_MODELS[\"footwear\"] = FOOTWEAR_EMBEDDING\n",
    "        print(\"Models Loaded!\")\n",
    "        return True\n",
    "    \n",
    "def load_CSVs():\n",
    "    \"\"\"\n",
    "    Load Various CSV files for Embedding Generation Pipeline\n",
    "    \"\"\"\n",
    "    if len(LOADED_CSVS) == 6:\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Loading CSVs...\")\n",
    "        MENS_TOPWEAR_CSV = pd.read_csv(\"..\\\\CSVS\\\\mens_topwear_embeddings.csv\")\n",
    "        MENS_BOTTOMWEAR_CSV = pd.read_csv(\"..\\\\CSVS\\\\mens_bottomwear_embeddings.csv\")\n",
    "        MENS_FOOTWEAR_CSV = pd.read_csv(\"..\\\\CSVS\\\\mens_footwear_embeddings.csv\")\n",
    "        WOMENS_TOPWEAR_CSV = pd.read_csv(\"..\\\\CSVS\\\\womens_topwear_embeddings.csv\")\n",
    "        WOMENS_BOTTOMWEAR_CSV = pd.read_csv(\"..\\\\CSVS\\\\womens_bottomwear_embeddings.csv\")\n",
    "        WOMENS_FOOTWEAR_CSV = pd.read_csv(\"..\\\\CSVS\\\\womens_footwear_embeddings.csv\")\n",
    "        \n",
    "        LOADED_CSVS[\"mens_topwear\"] = MENS_TOPWEAR_CSV\n",
    "        LOADED_CSVS[\"mens_bottomwear\"] = MENS_BOTTOMWEAR_CSV\n",
    "        LOADED_CSVS[\"mens_footwear\"] = MENS_FOOTWEAR_CSV\n",
    "        LOADED_CSVS[\"womens_topwear\"] = WOMENS_TOPWEAR_CSV\n",
    "        LOADED_CSVS[\"womens_bottomwear\"] = WOMENS_BOTTOMWEAR_CSV\n",
    "        LOADED_CSVS[\"womens_footwear\"] = WOMENS_FOOTWEAR_CSV\n",
    "        print(\"CSVs Loaded!\")\n",
    "        return True\n",
    "    \n",
    "def extract_clothes(image): \n",
    "    '''\n",
    "    Extract Topwear, Bottomwear and Footwear from a given Image\n",
    "    Note: In case there are multiple items of the same class, the item with highest confidence score is returned.\n",
    "    \n",
    "    Args:\n",
    "        image: Path to the image file that you want to extract clothes from.\n",
    "        \n",
    "    Returns:\n",
    "        ouputs: Dict[numpy.ndarray], Dictionary containing detected Object Class as Keys and the image slice as Values. Also contains the original image.\n",
    "    '''\n",
    "    temporary_image_storage = False\n",
    "    if isinstance(image, str):\n",
    "        img_path = image\n",
    "        image = io.imread(img_path)  \n",
    "    elif isinstance(image, np.ndarray):\n",
    "        img_path = os.path.join(\"temp\",\"example.jpg\")\n",
    "        saved_image = Image.fromarray(image)\n",
    "        saved_image.save(img_path)\n",
    "        temporary_image_storage = True\n",
    "    results = generate_bbox(img_path, conf_thres=0.3)\n",
    "    if temporary_image_storage:\n",
    "        os.remove(img_path)\n",
    "    topwear_score, bottomwear_score, footwear_score = 0, 0, 0\n",
    "    outputs = {\"original_image\": image}\n",
    "    for result in results[0]:\n",
    "        XMIN, YMIN, XMAX, YMAX = result[2]\n",
    "        if (result[0] == 'Topwear') and (result[1] > topwear_score):\n",
    "            topwear_score = result[1]\n",
    "            outputs[\"topwear\"] = image[YMIN:YMAX, XMIN:XMAX]\n",
    "        elif (result[0] == 'Bottomwear') and (result[1] > bottomwear_score):\n",
    "            bottomwear_score = result[1]\n",
    "            outputs[\"bottomwear\"] = image[YMIN:YMAX, XMIN:XMAX]\n",
    "        elif (result[0] == 'Footwear') and (result[1] > footwear_score):\n",
    "            footwear_score = result[1]\n",
    "            outputs[\"footwear\"] = image[YMIN:YMAX, XMIN:XMAX]\n",
    "    return outputs\n",
    "\n",
    "def plot_clothes(**images):\n",
    "    '''\n",
    "    Plot a dictionary of Images in a row\n",
    "    \n",
    "    Args:\n",
    "        Dict: Image Names and Images in numpy.ndarray format\n",
    "    \n",
    "    Returns:\n",
    "        matplotlib.figure object\n",
    "    '''\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "def generate_embedding(outputs, detected_objects):\n",
    "    \"\"\"\n",
    "    Generate Embeddings for Cropped Outputs from the Object Detection Module\n",
    "    \n",
    "    Args:\n",
    "        outputs: Dict[] objects containing Image slices for cropped detections\n",
    "        detected_objects: List[] names of the detected objects like topwear, bottomwear and footwear\n",
    "    \n",
    "    Returns:\n",
    "        outputs: Outputs with embeddings for each detected objects.\n",
    "    \"\"\"\n",
    "    for output in detected_objects:\n",
    "        image = outputs[output]\n",
    "        img_path = os.path.join(\"temp\",\"example.jpg\")\n",
    "        saved_image = Image.fromarray(image)\n",
    "        saved_image.save(img_path)\n",
    "        image = preprocess_image2(img_path)\n",
    "        embedding = LOADED_MODELS[output](image)[0].numpy().astype(np.float32).tolist()\n",
    "        outputs[output+\"_embedding\"] = embedding\n",
    "        os.remove(img_path)\n",
    "    return outputs\n",
    "\n",
    "def __get__(csv_file, query):\n",
    "    \"\"\"\n",
    "    Plot Top 10 similar products for each category along with the Product Link.\n",
    "    \"\"\"\n",
    "    csv_file['distance'] = csv_file['embedding'].apply(lambda x: np.linalg.norm(np.asarray(eval(x), dtype=np.float32) - np.asarray(query, dtype=np.float32)))\n",
    "    csv_file = csv_file.sort_values(by='distance').reset_index(drop=True)\n",
    "    result = csv_file.iloc[:10][['product_url', 'image_url']].to_dict('records')\n",
    "    for i, row in csv_file.iloc[:10].iterrows():\n",
    "        plt.figure(figsize=(16,9))\n",
    "        image = io.imread(\"..\\\\\"+row[\"image_path\"])\n",
    "        plt.imshow(image);plt.axis(\"off\");plt.show()\n",
    "        print(\"Shop Now @ \", row[\"product_url\"])\n",
    "        print(254*\"=\")\n",
    "    return result\n",
    "\n",
    "def get_results(outputs, gender, detected_objects):\n",
    "    \"\"\"\n",
    "    Get Similar products for a given input containing query product.\n",
    "    \"\"\"\n",
    "    dict_results = dict()\n",
    "    for output in detected_objects:\n",
    "        csv_file = gender + \"_\" + output\n",
    "        csv_file = LOADED_CSVS[csv_file].copy(deep=True)\n",
    "        query = outputs[output+\"_embedding\"]\n",
    "        dict_results[output] = __get__(csv_file, query)\n",
    "    return dict_results\n",
    "\n",
    "def final(images):\n",
    "    \"\"\"\n",
    "    The complete pipeline for recommending similar fashion products based on a query image.\n",
    "    \"\"\"\n",
    "    if isinstance(images, str):\n",
    "        images = [images]\n",
    "    if load_models() and load_CSVs():\n",
    "        for img_path in images:\n",
    "            inputs = preprocess_image1(img_path)\n",
    "            gender_score = LOADED_MODELS[\"gender_classifier\"](inputs)[0][0].numpy()\n",
    "            gender = \"mens\" if  gender_score < 0.5 else \"womens\"\n",
    "            outputs = extract_clothes(img_path)\n",
    "            detected_objects = [k for k in outputs if k != \"original_image\"]\n",
    "            plot_clothes(**outputs)\n",
    "            outputs = generate_embedding(outputs, detected_objects)\n",
    "            results = get_results(outputs, gender, detected_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_path = \"..\\\\google-image-search-database\\\\womens_casual_top_wear\\\\707be93f8e.jpg\"\n",
    "final(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_path = \"..\\\\google-image-search-database\\\\mens_formal_top_wear\\\\3cf46ceef5.jpg\"\n",
    "final(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_path = \"..\\\\google-image-search-database\\\\womens_casual_top_wear\\\\dd35ba9fdd.jpg\"\n",
    "final(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_path = \"..\\\\google-image-search-database\\\\mens_formal_top_wear\\\\f6c91729cb.jpg\"\n",
    "final(img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
